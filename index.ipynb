{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Text Classification - Cumulative Lab\n","\n","## Introduction\n","\n","In this cumulative lab, we'll use everything we've learned so far to build a model that can classify a text document as one of many possible classes!\n","\n","## Objectives\n","\n","You will be able to:\n","\n","- Practice cleaning and exploring a text dataset with NLTK and base Python\n","- Practice using scikit-learn vectorizers for text preprocessing\n","- Tune a modeling process through exploration and model evaluation\n","- Observe some techniques for feature engineering\n","- Interpret the result of a final ML model that classifies text data"]},{"cell_type":"markdown","metadata":{},"source":["## Your Task: Complete an End-to-End ML Process with the Newsgroups Dataset\n","\n","<a title=\"Bundesarchiv, B 145 Bild-F077948-0006 / Engelbert Reineke / CC-BY-SA 3.0, CC BY-SA 3.0 DE &lt;https://creativecommons.org/licenses/by-sa/3.0/de/deed.en&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Bundesarchiv_B_145_Bild-F077948-0006,_Jugend-Computerschule_mit_IBM-PC.jpg\"><img width=\"512\" alt=\"Bundesarchiv B 145 Bild-F077948-0006, Jugend-Computerschule mit IBM-PC\" src=\"https://upload.wikimedia.org/wikipedia/commons/e/e9/Bundesarchiv_B_145_Bild-F077948-0006%2C_Jugend-Computerschule_mit_IBM-PC.jpg\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["### Business Understanding\n","\n","The ***Newsgroups Dataset*** is a collection of [newsgroup](https://en.wikipedia.org/wiki/Usenet_newsgroup) posts originally collected around 1995. While the backend code implementation is fairly different, you can think of them as like the Reddit posts of 1995, where a \"category\" in this dataset is like a subreddit.\n","\n","The task is to try to identify the category where a post was published, based on the text content of the post.\n","\n","### Data Understanding\n","\n","#### Data Source\n","\n","Part of what you are practicing here is using the `sklearn.datasets` submodule, which you have seen before (e.g. the Iris Dataset, the Wine Dataset). You can see a full list of available dataset loaders [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets).\n","\n","In this case we will be using the `fetch_20newsgroups` function ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html)). An important thing to note is that because this is text data, scikit-learn actually downloads a set of documents to the computer you are using to complete this lab, rather than just loading data into memory in Python.\n","\n","#### Features\n","\n","Prior to preprocessing, every row in the dataset only contains one feature: a string containing the full text of the newsgroup post. We will perform preprocessing to create additional features.\n","\n","#### Target\n","\n","As you might have guessed based on the function name, there are 20 categories in the full dataset. Here is a list of all the possible classes:\n","\n","<img src='https://curriculum-content.s3.amazonaws.com/data-science/images/classes.png'>\n","\n","This full dataset is quite large. To save us from extremely long runtimes, we'll work with only a subset of the classes. For this lab, we'll work with the following five:\n","\n","* `'comp.windows.x'`\n","* `'rec.sport.hockey'`\n","* `'misc.forsale'`\n","* `'sci.crypt'`\n","* `'talk.politics.misc'`"]},{"cell_type":"markdown","metadata":{},"source":["### Requirements\n","\n","#### 1. Load the Data\n","\n","Use pandas and `sklearn.datasets` to load the train and test data into appropriate data structures. Then get a sense of what is in this dataset by visually inspecting some samples.\n","\n","#### 2. Perform Data Cleaning and Exploratory Data Analysis with `nltk`\n","\n","Standardize the case of the data and use a tokenizer to convert the full posts into lists of individual words. Then compare the raw word frequency distributions of each category.\n","\n","#### 3. Build and Evaluate a Baseline Model with `TfidfVectorizer` and `MultinomialNB`\n","\n","Ultimately all data must be in numeric form in order to be able to fit a scikit-learn model. So we'll use a tool from `sklearn.feature_extraction.text` to convert all data into a vectorized format.\n","\n","Initially we'll keep all of the default parameters for both the vectorizer and the model, in order to develop a baseline score.\n","\n","#### 4. Iteratively Perform and Evaluate Preprocessing and Feature Engineering Techniques\n","\n","Here you will investigate three techniques, to determine whether they should be part of our final modeling process:\n","\n","1. Removing stopwords\n","2. Using custom tokens\n","3. Domain-specific feature engineering\n","4. Increasing `max_features`\n","\n","#### 5. Evaluate a Final Model on the Test Set\n","\n","Once you have chosen a final modeling process, fit it on the full training data and evaluate it on the test data. "]},{"cell_type":"markdown","metadata":{},"source":["## 1. Load the Data\n","\n","In the cell below, create the variables `newsgroups_train` and `newsgroups_test` by calling the `fetch_20newsgroups` function twice.\n","\n","For the train set, specify `subset=\"train\"`. For the test set, specify `subset=\"test\"`.\n","\n","Additionally, pass in `remove=('headers', 'footers', 'quotes')` in both function calls, in order to automatically remove some metadata that can lead to overfitting.\n","\n","Recall that we are loading only five categories, out of the full 20. So, pass in `categories=categories` both times."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["# Replace None with appropriate code\n","from sklearn.datasets import fetch_20newsgroups\n","\n","categories = [\n","    'comp.windows.x',\n","    'rec.sport.hockey',\n","    'misc.forsale',\n","    'sci.crypt',\n","    'talk.politics.misc'\n","]\n","\n","newsgroups_train = fetch_20newsgroups(\n","    subset='train',\n","    remove=('headers', 'footers', 'quotes'),\n","    categories=categories\n",")\n","\n","newsgroups_test = fetch_20newsgroups(\n","    subset=\"test\",\n","    remove=('headers', 'footers', 'quotes'),\n","    categories=categories\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Each of the returned objects is a dictionary-like `Bunch` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html)):"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["sklearn.utils._bunch.Bunch"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","type(newsgroups_train)"]},{"cell_type":"markdown","metadata":{},"source":["The important thing to know is that the `.data` attribute will extract the feature values, and the `.target` attribute will extract the target values. So, for example, the train features (`X_train`) are located in `newsgroups_train.data`, whereas the train targets (`y_train`) are located in `newsgroups_train.target`.\n","\n","In the cell below, create `X_train`, `X_test`, `y_train`, `y_test` based on `newsgroups_train` and `newsgroups_test`."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Replace None with appropriate code\n","import pandas as pd\n","pd.set_option('max_colwidth', 400)\n","pd.set_option('use_mathjax', False)\n","\n","# Extract values from Bunch objects\n","X_train = pd.DataFrame(newsgroups_train.data, columns=[\"text\"])\n","X_test = pd.DataFrame(newsgroups_test.data, columns=[\"text\"])\n","y_train = pd.Series(newsgroups_train.target, name=\"category\")\n","y_test = pd.Series(newsgroups_test.target, name=\"category\")"]},{"cell_type":"markdown","metadata":{},"source":["Double-check that your variables have the correct shape below:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","\n","# X_train and X_test both have 1 column (text)\n","assert X_train.shape[1] == X_test.shape[1] and X_train.shape[1] == 1\n","\n","# y_train and y_test are 1-dimensional (target value only)\n","assert len(y_train.shape) == len(y_test.shape) and len(y_train.shape) == 1\n","\n","# X_train and y_train have the same number of rows\n","assert X_train.shape[0] == y_train.shape[0] and X_train.shape[0] == 2838\n","\n","# X_test and y_test have the same number of rows\n","assert X_test.shape[0] == y_test.shape[0] and X_test.shape[0] == 1890"]},{"cell_type":"markdown","metadata":{},"source":["And now let's look at some basic attributes of the dataset.\n","\n","#### Distribution of Target\n","\n","We know that there are five categories represented. How many are there of each?"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","      <th>target name</th>\n","    </tr>\n","    <tr>\n","      <th>target value</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>600</td>\n","      <td>rec.sport.hockey</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>595</td>\n","      <td>sci.crypt</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>593</td>\n","      <td>comp.windows.x</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>585</td>\n","      <td>misc.forsale</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>465</td>\n","      <td>talk.politics.misc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              count         target name\n","target value                           \n","2               600    rec.sport.hockey\n","3               595           sci.crypt\n","0               593      comp.windows.x\n","1               585        misc.forsale\n","4               465  talk.politics.misc"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","\n","train_target_counts = pd.DataFrame(y_train.value_counts())\n","train_target_counts[\"label\"] = [newsgroups_train.target_names[val] for val in train_target_counts.index]\n","train_target_counts.columns = [\"count\", \"target name\"]\n","train_target_counts.index.name = \"target value\"\n","train_target_counts"]},{"cell_type":"markdown","metadata":{},"source":["So, for example, the category \"comp.windows.x\" has the label of `0` in our dataset, and there are 593 text samples in that category within our training data.\n","\n","We also note that our target distribution looks reasonably balanced. Now let's look at the features.\n","\n","#### Visually Inspecting Features\n","\n","Run the cell below to view some examples of the features:"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_d9b4a_row0_col0, #T_d9b4a_row0_col1, #T_d9b4a_row1_col0, #T_d9b4a_row1_col1, #T_d9b4a_row2_col0, #T_d9b4a_row2_col1, #T_d9b4a_row3_col0, #T_d9b4a_row3_col1, #T_d9b4a_row4_col0, #T_d9b4a_row4_col1 {\n","  text-align: left;\n","}\n","</style>\n","<table id=\"T_d9b4a\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_d9b4a_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n","      <th id=\"T_d9b4a_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_d9b4a_level0_row0\" class=\"row_heading level0 row0\" >1300</th>\n","      <td id=\"T_d9b4a_row0_col0\" class=\"data row0 col0\" >\n","\n","\n","   Ncd has an excellent document titled \"Host Loading Considerations in the X \n","  environment\". I received my copy by emailing support@ncd.com. This may\n","  help out.</td>\n","      <td id=\"T_d9b4a_row0_col1\" class=\"data row0 col1\" >0</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_d9b4a_level0_row1\" class=\"row_heading level0 row1\" >1758</th>\n","      <td id=\"T_d9b4a_row1_col0\" class=\"data row1 col0\" >\n","\n"," \n","           You don't have to.  *It*  believes in YOU.\n","\n","\n","\n","\n","        Well, looking at our new government pals, I'm inclined to\n","        agree.  I don't much believe in our money, either. :)\n","\n","\n","\n","\n","    Oh, ho HO!   If only you knew!  :)\n","\n","    Yup, I'm DEFINITELY checking out foreign currency, thanks to\n","    to this newsgroup.  It sure doesn't take much thinking to realize\n","    what direction the U.S. is headed.\n","\n","\n","</td>\n","      <td id=\"T_d9b4a_row1_col1\" class=\"data row1 col1\" >4</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_d9b4a_level0_row2\" class=\"row_heading level0 row2\" >2558</th>\n","      <td id=\"T_d9b4a_row2_col0\" class=\"data row2 col0\" >Miscellaneous comics for sale. I really would like\n","to get rid of these for lack of space. Buyer pays\n","shipping, and all offers considered. OH, and the\n","first purchase over $20 in any of my posts\n","gets a free Maxx #1/2 coupon, or a trashed copy\n","of Amazing spidey #300. Here goes...\n","\n","\n","Deathlok         #1           $3.00\n","                 2-17         $1.75 each\n","                 Annual #1     2.50\n","                 Special #1    2.00\n","\n","Sleepwalker      1,2,6,8,9,13  7.00 (set) or 1.25\n","                                             each\n","\n","\n","Next Men         #1           $3.00\n","Ray              #1            1.00\n","Deathstroke      5,6           1.75 each\n","Darkhawk         13            1.25\n","New warrior's    18            1.00\n","Fantasti Four    358           2.50\n","Moon Knight      35,36         1.75 each\n","Hulk             386-388       1.50 each\n","\n","Punisher W.Z.    1             2.50\n","Cage             1             1.50\n","X-force          1             2.00\n","Silver Sable     1             2.00\n","X-calibur        26,27,48,49   1.50 each\n","\n","\n","Hearts of Darkness             5.00\n","Infinity Guantlet     1-4      2.50 each\n","Batman v. Pred.       1,3      2.00 each\n"," \"   \"  \"  (deluxe)   1        5.00\n","\n","Guardians of the\n","Galaxy                1       3.00\n","Spider-man 2099       1-3     5.00 (set)\n","Spec. spider-man      189     3.00 (special hologram)\n","\n","Let me know if you'd like to buy anything. My\n","address is U38134@uicvm.uic.edu</td>\n","      <td id=\"T_d9b4a_row2_col1\" class=\"data row2 col1\" >1</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_d9b4a_level0_row3\" class=\"row_heading level0 row3\" >2267</th>\n","      <td id=\"T_d9b4a_row3_col0\" class=\"data row3 col0\" >\n","\n","My vote goes to Andy Moog 1st, Belfour 2nd, Vanbiesbrouck 3rd\n","\n","The Bruin's are hot at just the right time !!!!!\n","\n","\n","rich beskosty</td>\n","      <td id=\"T_d9b4a_row3_col1\" class=\"data row3 col1\" >2</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_d9b4a_level0_row4\" class=\"row_heading level0 row4\" >1043</th>\n","      <td id=\"T_d9b4a_row4_col0\" class=\"data row4 col0\" >\n","\n","Yes, \"Clipper\" is a trademark of Intergraph.  Its the RISC chip used\n","in some of thier workstations. \n","\n","I wonder what Intergraph is going to do to this infringement on thier\n","name sake?\n","</td>\n","      <td id=\"T_d9b4a_row4_col1\" class=\"data row4 col1\" >3</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1fbf032a000>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","\n","# Sample 5 records and display full text of each\n","train_sample = X_train.sample(5, random_state=22)\n","train_sample[\"label\"] = [y_train[val] for val in train_sample.index]\n","train_sample.style.set_properties(**{'text-align': 'left'})"]},{"cell_type":"markdown","metadata":{},"source":["In order, we have:\n","\n","* An example of `comp.windows.x`, talking about \"host loading considerations\"\n","* An example of `talk.politics.misc`, talking about government and currency\n","* An example of `misc.forsale`, talking about a list of comics for sale\n","* An example of `rec.sport.hockey`, talking about hockey players and the Bruins\n","* An example of `sci.crypt`, talking about a microprocessor\n","\n","We appear to have loaded the data correctly, so let's move on and perform some cleaning and additional exploratory analysis."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Perform Data Cleaning and Exploratory Data Analysis with `nltk`\n","\n","Prior to any exploratory analysis, we'll complete two common data cleaning tasks for text data: standardizing case and tokenizing.\n","\n","### Standardizing Case\n","\n","In an NLP modeling process, sometimes we will want to preserve the original case of words (i.e. to treat `\"It\"` and `\"it\"` as different words, and sometimes we will want to standardize case (i.e. to treat `\"It\"` and `\"it\"` as the same word).\n","\n","To figure out what we want to do, let's look at the first sample from above:"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["'\\n\\n\\n   Ncd has an excellent document titled \"Host Loading Considerations in the X \\n  environment\". I received my copy by emailing support@ncd.com. This may\\n  help out.'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","windows_sample = train_sample.iloc[0][\"text\"]\n","windows_sample"]},{"cell_type":"markdown","metadata":{},"source":["Here we have two references to the company Network Computing Devices, or NCD. At the beginning, the poster refers to it as `\"Ncd\"`. Then later refers to `\"support@ncd.com\"`. It seems reasonable to assume that both of these should be treated as references to the same word instead of treating `\"Ncd\"` and `\"ncd\"` as two totally separate things. So let's standardize the case of all letters in this dataset.\n","\n","The typical way to standardize case is to make everything lowercase. While it's possible to do this after tokenizing, it's easier and faster to do it first.\n","\n","For a single sample, we can just use the built-in Python `.lower()` method:"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["'\\n\\n\\n   ncd has an excellent document titled \"host loading considerations in the x \\n  environment\". i received my copy by emailing support@ncd.com. this may\\n  help out.'"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","windows_sample.lower()"]},{"cell_type":"markdown","metadata":{},"source":["#### Standarizing Case in the Full Dataset\n","\n","To access this method in pandas, you use `.str.lower()`:"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_c7288_row0_col0, #T_c7288_row0_col1, #T_c7288_row1_col0, #T_c7288_row1_col1, #T_c7288_row2_col0, #T_c7288_row2_col1, #T_c7288_row3_col0, #T_c7288_row3_col1, #T_c7288_row4_col0, #T_c7288_row4_col1 {\n","  text-align: left;\n","}\n","</style>\n","<table id=\"T_c7288\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_c7288_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n","      <th id=\"T_c7288_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_c7288_level0_row0\" class=\"row_heading level0 row0\" >1300</th>\n","      <td id=\"T_c7288_row0_col0\" class=\"data row0 col0\" >\n","\n","\n","   ncd has an excellent document titled \"host loading considerations in the x \n","  environment\". i received my copy by emailing support@ncd.com. this may\n","  help out.</td>\n","      <td id=\"T_c7288_row0_col1\" class=\"data row0 col1\" >0</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c7288_level0_row1\" class=\"row_heading level0 row1\" >1758</th>\n","      <td id=\"T_c7288_row1_col0\" class=\"data row1 col0\" >\n","\n"," \n","           you don't have to.  *it*  believes in you.\n","\n","\n","\n","\n","        well, looking at our new government pals, i'm inclined to\n","        agree.  i don't much believe in our money, either. :)\n","\n","\n","\n","\n","    oh, ho ho!   if only you knew!  :)\n","\n","    yup, i'm definitely checking out foreign currency, thanks to\n","    to this newsgroup.  it sure doesn't take much thinking to realize\n","    what direction the u.s. is headed.\n","\n","\n","</td>\n","      <td id=\"T_c7288_row1_col1\" class=\"data row1 col1\" >4</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c7288_level0_row2\" class=\"row_heading level0 row2\" >2558</th>\n","      <td id=\"T_c7288_row2_col0\" class=\"data row2 col0\" >miscellaneous comics for sale. i really would like\n","to get rid of these for lack of space. buyer pays\n","shipping, and all offers considered. oh, and the\n","first purchase over $20 in any of my posts\n","gets a free maxx #1/2 coupon, or a trashed copy\n","of amazing spidey #300. here goes...\n","\n","\n","deathlok         #1           $3.00\n","                 2-17         $1.75 each\n","                 annual #1     2.50\n","                 special #1    2.00\n","\n","sleepwalker      1,2,6,8,9,13  7.00 (set) or 1.25\n","                                             each\n","\n","\n","next men         #1           $3.00\n","ray              #1            1.00\n","deathstroke      5,6           1.75 each\n","darkhawk         13            1.25\n","new warrior's    18            1.00\n","fantasti four    358           2.50\n","moon knight      35,36         1.75 each\n","hulk             386-388       1.50 each\n","\n","punisher w.z.    1             2.50\n","cage             1             1.50\n","x-force          1             2.00\n","silver sable     1             2.00\n","x-calibur        26,27,48,49   1.50 each\n","\n","\n","hearts of darkness             5.00\n","infinity guantlet     1-4      2.50 each\n","batman v. pred.       1,3      2.00 each\n"," \"   \"  \"  (deluxe)   1        5.00\n","\n","guardians of the\n","galaxy                1       3.00\n","spider-man 2099       1-3     5.00 (set)\n","spec. spider-man      189     3.00 (special hologram)\n","\n","let me know if you'd like to buy anything. my\n","address is u38134@uicvm.uic.edu</td>\n","      <td id=\"T_c7288_row2_col1\" class=\"data row2 col1\" >1</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c7288_level0_row3\" class=\"row_heading level0 row3\" >2267</th>\n","      <td id=\"T_c7288_row3_col0\" class=\"data row3 col0\" >\n","\n","my vote goes to andy moog 1st, belfour 2nd, vanbiesbrouck 3rd\n","\n","the bruin's are hot at just the right time !!!!!\n","\n","\n","rich beskosty</td>\n","      <td id=\"T_c7288_row3_col1\" class=\"data row3 col1\" >2</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_c7288_level0_row4\" class=\"row_heading level0 row4\" >1043</th>\n","      <td id=\"T_c7288_row4_col0\" class=\"data row4 col0\" >\n","\n","yes, \"clipper\" is a trademark of intergraph.  its the risc chip used\n","in some of thier workstations. \n","\n","i wonder what intergraph is going to do to this infringement on thier\n","name sake?\n","</td>\n","      <td id=\"T_c7288_row4_col1\" class=\"data row4 col1\" >3</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1fbf59270e0>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","\n","# Transform sample data to lowercase\n","train_sample[\"text\"] = train_sample[\"text\"].str.lower()\n","# Display full text\n","train_sample.style.set_properties(**{'text-align': 'left'})"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, perform the same operation on the full `X_train`:"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Replace None with appropriate code\n","\n","# Transform text in X_train to lowercase\n","X_train = [text.lower() for text in X_train]"]},{"cell_type":"markdown","metadata":{},"source":["Double-check your work by looking at an example and making sure the text is lowercase:"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["# Run this cell without changes\n","X_train.iloc[100][\"text\"]"]},{"cell_type":"markdown","metadata":{},"source":["### Tokenizing\n","\n","Now that the case is consistent it's time to convert each document from a single long string into a set of tokens.\n","\n","Let's look more closely at the second example from our training data sample:"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["\"\\n\\n \\n           you don't have to.  *it*  believes in you.\\n\\n\\n\\n\\n        well, looking at our new government pals, i'm inclined to\\n        agree.  i don't much believe in our money, either. :)\\n\\n\\n\\n\\n    oh, ho ho!   if only you knew!  :)\\n\\n    yup, i'm definitely checking out foreign currency, thanks to\\n    to this newsgroup.  it sure doesn't take much thinking to realize\\n    what direction the u.s. is headed.\\n\\n\\n\""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","politics_sample = train_sample.iloc[1][\"text\"]\n","politics_sample"]},{"cell_type":"markdown","metadata":{},"source":["If we split this into tokens just by using the built-in Python `.split` string method, we would have a lot of punctuation attached:"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["['you',\n"," \"don't\",\n"," 'have',\n"," 'to.',\n"," '*it*',\n"," 'believes',\n"," 'in',\n"," 'you.',\n"," 'well,',\n"," 'looking']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","politics_sample.split()[:10]"]},{"cell_type":"markdown","metadata":{},"source":["(Punctuation being attached to words is a problem because we probably want to treat `you` and `you.` as two instances of the same token, not two different tokens.)\n","\n","Let's use the default token pattern that scikit-learn uses in its vectorizers. The RegEx looks like this:\n","\n","```\n","(?u)\\b\\w\\w+\\b\n","```\n","\n","That means:\n","\n","1. `(?u)`: use full unicode string matching\n","2. `\\b`: find a word boundary (a word boundary has length 0, and represents the location between non-word characters and word characters)\n","3. `\\w\\w+`: find 2 or more word characters (all letters, numbers, and underscores are word characters)\n","4. `\\b`: find another word boundary\n","\n","In other words, we are looking for tokens that consist of two or more consecutive word characters, which include letters, numbers, and underscores.\n","\n","We'll use the `RegexpTokenizer` from NLTK to create these tokens, initially just transforming the politics sample:"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/plain":["['you', 'don', 'have', 'to', 'it', 'believes', 'in', 'you', 'well', 'looking']"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","\n","from nltk.tokenize import RegexpTokenizer\n","\n","basic_token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n","\n","tokenizer = RegexpTokenizer(basic_token_pattern)\n","tokenizer.tokenize(politics_sample)[:10]"]},{"cell_type":"markdown","metadata":{},"source":["#### Tokenizing the Full Dataset\n","\n","The way to tokenize all values in a column of a pandas dataframe is to use `.apply` and pass in `tokenizer.tokenize`.\n","\n","For example, with the sample dataset:"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<style type=\"text/css\">\n","#T_6deb6_row0_col0, #T_6deb6_row0_col1, #T_6deb6_row0_col2, #T_6deb6_row1_col0, #T_6deb6_row1_col1, #T_6deb6_row1_col2, #T_6deb6_row2_col0, #T_6deb6_row2_col1, #T_6deb6_row2_col2, #T_6deb6_row3_col0, #T_6deb6_row3_col1, #T_6deb6_row3_col2, #T_6deb6_row4_col0, #T_6deb6_row4_col1, #T_6deb6_row4_col2 {\n","  text-align: left;\n","}\n","</style>\n","<table id=\"T_6deb6\">\n","  <thead>\n","    <tr>\n","      <th class=\"blank level0\" >&nbsp;</th>\n","      <th id=\"T_6deb6_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n","      <th id=\"T_6deb6_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n","      <th id=\"T_6deb6_level0_col2\" class=\"col_heading level0 col2\" >text_tokenized</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th id=\"T_6deb6_level0_row0\" class=\"row_heading level0 row0\" >1300</th>\n","      <td id=\"T_6deb6_row0_col0\" class=\"data row0 col0\" >\n","\n","\n","   ncd has an excellent document titled \"host loading considerations in the x \n","  environment\". i received my copy by emailing support@ncd.com. this may\n","  help out.</td>\n","      <td id=\"T_6deb6_row0_col1\" class=\"data row0 col1\" >0</td>\n","      <td id=\"T_6deb6_row0_col2\" class=\"data row0 col2\" >['ncd', 'has', 'an', 'excellent', 'document', 'titled', 'host', 'loading', 'considerations', 'in', 'the', 'environment', 'received', 'my', 'copy', 'by', 'emailing', 'support', 'ncd', 'com', 'this', 'may', 'help', 'out']</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6deb6_level0_row1\" class=\"row_heading level0 row1\" >1758</th>\n","      <td id=\"T_6deb6_row1_col0\" class=\"data row1 col0\" >\n","\n"," \n","           you don't have to.  *it*  believes in you.\n","\n","\n","\n","\n","        well, looking at our new government pals, i'm inclined to\n","        agree.  i don't much believe in our money, either. :)\n","\n","\n","\n","\n","    oh, ho ho!   if only you knew!  :)\n","\n","    yup, i'm definitely checking out foreign currency, thanks to\n","    to this newsgroup.  it sure doesn't take much thinking to realize\n","    what direction the u.s. is headed.\n","\n","\n","</td>\n","      <td id=\"T_6deb6_row1_col1\" class=\"data row1 col1\" >4</td>\n","      <td id=\"T_6deb6_row1_col2\" class=\"data row1 col2\" >['you', 'don', 'have', 'to', 'it', 'believes', 'in', 'you', 'well', 'looking', 'at', 'our', 'new', 'government', 'pals', 'inclined', 'to', 'agree', 'don', 'much', 'believe', 'in', 'our', 'money', 'either', 'oh', 'ho', 'ho', 'if', 'only', 'you', 'knew', 'yup', 'definitely', 'checking', 'out', 'foreign', 'currency', 'thanks', 'to', 'to', 'this', 'newsgroup', 'it', 'sure', 'doesn', 'take', 'much', 'thinking', 'to', 'realize', 'what', 'direction', 'the', 'is', 'headed']</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6deb6_level0_row2\" class=\"row_heading level0 row2\" >2558</th>\n","      <td id=\"T_6deb6_row2_col0\" class=\"data row2 col0\" >miscellaneous comics for sale. i really would like\n","to get rid of these for lack of space. buyer pays\n","shipping, and all offers considered. oh, and the\n","first purchase over $20 in any of my posts\n","gets a free maxx #1/2 coupon, or a trashed copy\n","of amazing spidey #300. here goes...\n","\n","\n","deathlok         #1           $3.00\n","                 2-17         $1.75 each\n","                 annual #1     2.50\n","                 special #1    2.00\n","\n","sleepwalker      1,2,6,8,9,13  7.00 (set) or 1.25\n","                                             each\n","\n","\n","next men         #1           $3.00\n","ray              #1            1.00\n","deathstroke      5,6           1.75 each\n","darkhawk         13            1.25\n","new warrior's    18            1.00\n","fantasti four    358           2.50\n","moon knight      35,36         1.75 each\n","hulk             386-388       1.50 each\n","\n","punisher w.z.    1             2.50\n","cage             1             1.50\n","x-force          1             2.00\n","silver sable     1             2.00\n","x-calibur        26,27,48,49   1.50 each\n","\n","\n","hearts of darkness             5.00\n","infinity guantlet     1-4      2.50 each\n","batman v. pred.       1,3      2.00 each\n"," \"   \"  \"  (deluxe)   1        5.00\n","\n","guardians of the\n","galaxy                1       3.00\n","spider-man 2099       1-3     5.00 (set)\n","spec. spider-man      189     3.00 (special hologram)\n","\n","let me know if you'd like to buy anything. my\n","address is u38134@uicvm.uic.edu</td>\n","      <td id=\"T_6deb6_row2_col1\" class=\"data row2 col1\" >1</td>\n","      <td id=\"T_6deb6_row2_col2\" class=\"data row2 col2\" >['miscellaneous', 'comics', 'for', 'sale', 'really', 'would', 'like', 'to', 'get', 'rid', 'of', 'these', 'for', 'lack', 'of', 'space', 'buyer', 'pays', 'shipping', 'and', 'all', 'offers', 'considered', 'oh', 'and', 'the', 'first', 'purchase', 'over', '20', 'in', 'any', 'of', 'my', 'posts', 'gets', 'free', 'maxx', 'coupon', 'or', 'trashed', 'copy', 'of', 'amazing', 'spidey', '300', 'here', 'goes', 'deathlok', '00', '17', '75', 'each', 'annual', '50', 'special', '00', 'sleepwalker', '13', '00', 'set', 'or', '25', 'each', 'next', 'men', '00', 'ray', '00', 'deathstroke', '75', 'each', 'darkhawk', '13', '25', 'new', 'warrior', '18', '00', 'fantasti', 'four', '358', '50', 'moon', 'knight', '35', '36', '75', 'each', 'hulk', '386', '388', '50', 'each', 'punisher', '50', 'cage', '50', 'force', '00', 'silver', 'sable', '00', 'calibur', '26', '27', '48', '49', '50', 'each', 'hearts', 'of', 'darkness', '00', 'infinity', 'guantlet', '50', 'each', 'batman', 'pred', '00', 'each', 'deluxe', '00', 'guardians', 'of', 'the', 'galaxy', '00', 'spider', 'man', '2099', '00', 'set', 'spec', 'spider', 'man', '189', '00', 'special', 'hologram', 'let', 'me', 'know', 'if', 'you', 'like', 'to', 'buy', 'anything', 'my', 'address', 'is', 'u38134', 'uicvm', 'uic', 'edu']</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6deb6_level0_row3\" class=\"row_heading level0 row3\" >2267</th>\n","      <td id=\"T_6deb6_row3_col0\" class=\"data row3 col0\" >\n","\n","my vote goes to andy moog 1st, belfour 2nd, vanbiesbrouck 3rd\n","\n","the bruin's are hot at just the right time !!!!!\n","\n","\n","rich beskosty</td>\n","      <td id=\"T_6deb6_row3_col1\" class=\"data row3 col1\" >2</td>\n","      <td id=\"T_6deb6_row3_col2\" class=\"data row3 col2\" >['my', 'vote', 'goes', 'to', 'andy', 'moog', '1st', 'belfour', '2nd', 'vanbiesbrouck', '3rd', 'the', 'bruin', 'are', 'hot', 'at', 'just', 'the', 'right', 'time', 'rich', 'beskosty']</td>\n","    </tr>\n","    <tr>\n","      <th id=\"T_6deb6_level0_row4\" class=\"row_heading level0 row4\" >1043</th>\n","      <td id=\"T_6deb6_row4_col0\" class=\"data row4 col0\" >\n","\n","yes, \"clipper\" is a trademark of intergraph.  its the risc chip used\n","in some of thier workstations. \n","\n","i wonder what intergraph is going to do to this infringement on thier\n","name sake?\n","</td>\n","      <td id=\"T_6deb6_row4_col1\" class=\"data row4 col1\" >3</td>\n","      <td id=\"T_6deb6_row4_col2\" class=\"data row4 col2\" >['yes', 'clipper', 'is', 'trademark', 'of', 'intergraph', 'its', 'the', 'risc', 'chip', 'used', 'in', 'some', 'of', 'thier', 'workstations', 'wonder', 'what', 'intergraph', 'is', 'going', 'to', 'do', 'to', 'this', 'infringement', 'on', 'thier', 'name', 'sake']</td>\n","    </tr>\n","  </tbody>\n","</table>\n"],"text/plain":["<pandas.io.formats.style.Styler at 0x1fbf6fb63f0>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","\n","# Create new column with tokenized data\n","train_sample[\"text_tokenized\"] = train_sample[\"text\"].apply(tokenizer.tokenize)\n","# Display full text\n","train_sample.style.set_properties(**{'text-align': 'left'})"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, apply the same operation on `X_train`:"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["from nltk.tokenize import WhitespaceTokenizer\n","\n","# Define the tokenizer object\n","tokenizer = WhitespaceTokenizer()\n","\n","# Create column text_tokenized on X_train\n","X_train_tokenized = [tokenizer.tokenize(text) for text in X_train]"]},{"cell_type":"markdown","metadata":{},"source":["Visually inspect your work below:"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_tokenized\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m20\u001b[39m]\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"]}],"source":["# Run this cell without changes\n","X_train.iloc[100][\"text_tokenized\"][:20]"]},{"cell_type":"markdown","metadata":{},"source":["(Note that we have removed all single-letter words, so instead of `\"have\", \"a\", \"problem\"`, the sample now shows just `\"have\", \"problem\"`. If we wanted to include single-letter words, we could use the token pattern `(?u)\\b\\w+\\b` instead.)\n","\n","Now that our data is cleaned up (case standardized and tokenized), we can perform some EDA."]},{"cell_type":"markdown","metadata":{},"source":["### Exploratory Data Analysis: Frequency Distributions\n","\n","Recall that a frequency distribution is a data structure that contains pieces of data as well as the count of how frequently they appear. In this case, the pieces of data we'll be looking at are tokens (words).\n","\n","In the past we have built a frequency distribution \"by hand\" using built-in Python data structures. Here we'll use another handy tool from NLTK called `FreqDist` ([documentation here](http://www.nltk.org/api/nltk.html?highlight=freqdist#nltk.probability.FreqDist)). `FreqDist` allows us to pass in a single list of words, and it produces a dictionary-like output of those words and their frequencies.\n","\n","For example, this creates a frequency distribution of the example shown above:"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"list index out of range","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[43], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FreqDist\n\u001b[1;32m----> 4\u001b[0m example_freq_dist \u001b[38;5;241m=\u001b[39m FreqDist(\u001b[43mX_train_tokenized\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m20\u001b[39m])\n\u001b[0;32m      5\u001b[0m example_freq_dist\n","\u001b[1;31mIndexError\u001b[0m: list index out of range"]}],"source":["# Run this cell without changes\n","from nltk import FreqDist\n","\n","example_freq_dist = FreqDist(X_train.iloc[100][\"text_tokenized\"][:20])\n","example_freq_dist"]},{"cell_type":"markdown","metadata":{},"source":["Then can use Matplotlib to visualize the most common words:"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'example_freq_dist' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[44], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     ax\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mset_major_locator(MaxNLocator(integer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     20\u001b[0m     ax\u001b[38;5;241m.\u001b[39mtick_params(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m visualize_top_10(\u001b[43mexample_freq_dist\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 10 Word Frequency for Example Tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'example_freq_dist' is not defined"]}],"source":["# Run this cell without changes\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import MaxNLocator\n","\n","def visualize_top_10(freq_dist, title):\n","\n","    # Extract data for plotting\n","    top_10 = list(zip(*freq_dist.most_common(10)))\n","    tokens = top_10[0]\n","    counts = top_10[1]\n","\n","    # Set up plot and plot data\n","    fig, ax = plt.subplots()\n","    ax.bar(tokens, counts)\n","\n","    # Customize plot appearance\n","    ax.set_title(title)\n","    ax.set_ylabel(\"Count\")\n","    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n","    ax.tick_params(axis=\"x\", rotation=90)\n","    \n","visualize_top_10(example_freq_dist, \"Top 10 Word Frequency for Example Tokens\")"]},{"cell_type":"markdown","metadata":{},"source":["Interpreting the chart above is a bit artificial, since this sample only included 20 tokens. But essentially this is saying that the token with the highest frequency in our example is `\"is\"`, which occurred twice."]},{"cell_type":"markdown","metadata":{},"source":["#### Visualizing the Frequency Distribution for the Full Dataset\n","\n","Let's do that for the full `X_train`.\n","\n","First, we need a list of all of the words in the `text_tokenized` column. We could do this manually by looping over the rows, but fortunately pandas has a handy method called `.explode()` ([documentation here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.explode.html#pandas.Series.explode)) that does exactly this.\n","\n","Here is an example applying that to the sample dataframe:"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"data":{"text/plain":["1300             ncd\n","1300             has\n","1300              an\n","1300       excellent\n","1300        document\n","            ...     \n","1043    infringement\n","1043              on\n","1043           thier\n","1043            name\n","1043            sake\n","Name: text_tokenized, Length: 289, dtype: object"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","train_sample[\"text_tokenized\"].explode()"]},{"cell_type":"markdown","metadata":{},"source":["And we can visualize the top 10 words from the sample dataframe like this:"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Run this cell without changes\n","sample_freq_dist = FreqDist(train_sample[\"text_tokenized\"].explode())\n","visualize_top_10(sample_freq_dist, \"Top 10 Word Frequency for 5 Samples\")"]},{"cell_type":"markdown","metadata":{},"source":["Note that `\"00\"` and `\"50\"` are both in the top 10 tokens, due to many prices appearing in the `misc.forsale` example.\n","\n","In the cell below, complete the same process for the full `X_train`:"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Replace None with appropriate code\n","from nltk import FreqDist\n","import matplotlib.pyplot as plt\n","# Create a frequency distribution for X_train\n","train_freq_dist = FreqDist(token for tokens in X_train_tokenized for token in tokens)\n","\n","# Plot the top 10 tokens\n","train_freq_dist.plot(10)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Ok great, we have a general sense of the word frequencies in our dataset!\n","\n","We can also subdivide this by category, to see if it makes a difference:"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'text_tokenized'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'text_tokenized'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[49], line 56\u001b[0m\n\u001b[0;32m     52\u001b[0m         ax\u001b[38;5;241m.\u001b[39mtick_params(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, rotation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m90\u001b[39m)\n\u001b[0;32m     55\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m setup_five_subplots()\n\u001b[1;32m---> 56\u001b[0m \u001b[43mplot_distribution_of_column_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_tokenized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Frequencies for All Tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m);\n","Cell \u001b[1;32mIn[49], line 38\u001b[0m, in \u001b[0;36mplot_distribution_of_column_by_category\u001b[1;34m(column, axes, title)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_distribution_of_column_by_category\u001b[39m(column, axes, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Frequency for\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(newsgroups_train\u001b[38;5;241m.\u001b[39mtarget_names):\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# Calculate frequency distribution for this subset\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m         all_words \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mexplode()\n\u001b[0;32m     39\u001b[0m         freq_dist \u001b[38;5;241m=\u001b[39m FreqDist(all_words)\n\u001b[0;32m     40\u001b[0m         top_10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfreq_dist\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)))\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'text_tokenized'"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x900 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Run this cell without changes\n","import pandas as pd\n","X_train_df = pd.DataFrame(X_train, columns=[\"text\"])\n","\n","# Add in labels for filtering (we won't pass them in to the model)\n","X_train_df[\"label\"] = [y_train[val] for val in range(len(X_train))]\n","\n","def setup_five_subplots():\n","    \"\"\"\n","    It's hard to make an odd number of graphs pretty with just nrows\n","    and ncols, so we make a custom grid. See example for more details:\n","    https://matplotlib.org/stable/gallery/subplots_axes_and_figures/gridspec_multicolumn.html\n","\n","    We want the graphs to look like this:\n","     [ ] [ ] [ ]\n","       [ ] [ ]\n","\n","    So we make a 2x6 grid with 5 graphs arranged on it. 3 in the\n","    top row, 2 in the second row\n","\n","      0 1 2 3 4 5\n","    0|[|]|[|]|[|]|\n","    1| |[|]|[|]| |\n","    \"\"\"\n","    fig = plt.figure(figsize=(15,9))\n","    fig.set_tight_layout(True)\n","    gs = fig.add_gridspec(2, 6)\n","    ax1 = fig.add_subplot(gs[0, :2]) # row 0, cols 0-1\n","    ax2 = fig.add_subplot(gs[0, 2:4])# row 0, cols 2-3\n","    ax3 = fig.add_subplot(gs[0, 4:]) # row 0, cols 4-5\n","    ax4 = fig.add_subplot(gs[1, 1:3])# row 1, cols 1-2\n","    ax5 = fig.add_subplot(gs[1, 3:5])# row 1, cols 3-4\n","    return fig, [ax1, ax2, ax3, ax4, ax5]\n","\n","def plot_distribution_of_column_by_category(column, axes, title=\"Word Frequency for\"):\n","    for index, category in enumerate(newsgroups_train.target_names):\n","        # Calculate frequency distribution for this subset\n","        all_words = X_train_df[X_train_df[\"label\"] == index][column].explode()\n","        freq_dist = FreqDist(all_words)\n","        top_10 = list(zip(*freq_dist.most_common(10)))\n","        tokens = top_10[0]\n","        counts = top_10[1]\n","\n","        # Set up plot\n","        ax = axes[index]\n","        ax.bar(tokens, counts)\n","\n","        # Customize plot appearance\n","        ax.set_title(f\"{title} {category}\")\n","        ax.set_ylabel(\"Count\")\n","        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n","        ax.tick_params(axis=\"x\", rotation=90)\n","\n","\n","fig, axes = setup_five_subplots()\n","plot_distribution_of_column_by_category(\"text_tokenized\", axes)\n","fig.suptitle(\"Word Frequencies for All Tokens\", fontsize=24);"]},{"cell_type":"markdown","metadata":{},"source":["If these were unlabeled, would you be able to figure out which one matched with which category?\n","\n","Well, `misc.forsale` still has a number (`\"00\"`) as one of its top tokens, so you might be able to figure out that one, but it seems very difficult to distinguish the others; every single category has `\"the\"` as the most common token, and every category except for `misc.forsale` has `\"to\"` as the second most common token. \n","\n","After building our baseline model, we'll use this information to inform our next preprocessing steps."]},{"cell_type":"markdown","metadata":{},"source":["## 3. Build and Evaluate a Baseline Model with `TfidfVectorizer` and `MultinomialNB`\n","\n","Let's start modeling by building a model that basically only has access to the information in the plots above. So, using the default token pattern to split the full text into tokens, and using a limited vocabulary.\n","\n","To give the model a little bit more information with those same features, we'll use a `TfidfVectorizer` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)) so that it counts not only the term frequency (`tf`) within a single document, it also includes the inverse document frequency (`idf`)  how rare the term is.\n","\n","In the cell below, import the vectorizer, instantiate a vectorizer object, and fit it on `X_train[\"text\"]`."]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   text\n","0   1.0"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["# Import the relevant vectorizer class\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import pandas as pd\n","\n","# Instantiate a vectorizer with max_features=10\n","# (we are using the default token pattern)\n","tfidf = TfidfVectorizer(max_features=10)\n","\n","# Fit the vectorizer on X_train[\"text\"] and transform it\n","X_train_vectorized = tfidf.fit_transform(X_train_df[\"text\"])\n","\n","# Visually inspect the 10 most common words\n","pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names_out())"]},{"cell_type":"markdown","metadata":{},"source":["Check the shape of your vectorized data:"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'shape'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[51], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# We should still have the same number of rows\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_train_vectorized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# The vectorized version should have 10 columns, since we set\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# max_features=10\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_train_vectorized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m10\u001b[39m\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}],"source":["# Run this cell without changes\n","\n","# We should still have the same number of rows\n","assert X_train_vectorized.shape[0] == X_train.shape[0]\n","\n","# The vectorized version should have 10 columns, since we set\n","# max_features=10\n","assert X_train_vectorized.shape[1] == 10"]},{"cell_type":"markdown","metadata":{},"source":["Now that we have preprocessed data, fit and evaluate a multinomial Naive Bayes classifier ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)) using `cross_val_score` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html))."]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1, 2838]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[54], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m baseline_model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier on X_train_vectorized and y_train\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m baseline_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m baseline_cv\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train_vectorized\u001b[38;5;241m.\u001b[39mshape)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:351\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[1;32m--> 351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:517\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    516\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 517\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    463\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2838]"]}],"source":["# Import relevant class and function\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import cross_val_score\n","\n","# Instantiate a MultinomialNB classifier\n","baseline_model = MultinomialNB()\n","\n","# Evaluate the classifier on X_train_vectorized and y_train\n","baseline_cv = cross_val_score(baseline_model, X_train_vectorized, y_train, cv=5)\n","baseline_cv"]},{"cell_type":"markdown","metadata":{},"source":["How well is this model performing? Well, recall the class balance:"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"data":{"text/plain":["category\n","2    0.211416\n","3    0.209655\n","0    0.208950\n","1    0.206131\n","4    0.163848\n","Name: proportion, dtype: float64"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","y_train.value_counts(normalize=True)"]},{"cell_type":"markdown","metadata":{},"source":["If we guessed the plurality class every time (class `2`), we would expect about 21% accuracy. So when this model is getting 37-42% accuracy, that is a clear improvement over just guessing. But with an accuracy below 50%, we still expect the model to guess the wrong class the majority of the time. Let's see if we can improve that with more sophisticated preprocessing."]},{"cell_type":"markdown","metadata":{},"source":["## 4. Iteratively Perform and Evaluate Preprocessing and Feature Engineering Techniques\n","\n","Now that we have our baseline, the fun part begins. As you've seen throughout this section, preprocessing text data is a bit more challenging that working with more traditional data types because there's no clear-cut answer for exactly what sort of preprocessing we need to do. As we are preprocessing our text data, we need to make some decisions about things such as:\n","\n","* Do we remove stop words or not?\n","* What should be counted as a token? Do we stem or lemmatize our text data, or leave the words as is? Do we want to include non-\"words\" in our tokens?\n","* Do we engineer other features, such as bigrams, or POS tags, or Mutual Information Scores?\n","* Do we use the entire vocabulary, or just limit the model to a subset of the most frequently used words? If so, how many?\n","* What sort of vectorization should we use in our model? Boolean Vectorization? Count Vectorization? TF-IDF? More advanced vectorization strategies such as Word2Vec?\n","\n","In this lab, we will work through the first four of these."]},{"cell_type":"markdown","metadata":{},"source":["### Removing Stopwords\n","\n","Let's begin with the first question: ***do we remove stopwords or not?*** In general we assume that stopwords do not contain useful information, but that is not always the case. Let's empirically investigate the top word frequencies of each category to see whether removing stopwords helps us to distinguish between the catogories.\n","\n","As-is, recall that the raw word frequency distributions of 4 out of 5 categories look very similar. They start with `the` as the word with by far the highest frequency, then there is a downward slope of other common words, starting with `to`. The `misc.forsale` category looks a little different, but it still has `the` as the top token.\n","\n","If we remove stopwords, how does this change the frequency distributions for each category?\n","\n","#### Stopwords List\n","\n","Once again, NLTK has a useful tool for this task. You can just import a list of standard stopwords:"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his']"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","import nltk\n","nltk.download('stopwords', quiet=True)\n","from nltk.corpus import stopwords\n","\n","stopwords_list = stopwords.words('english')\n","stopwords_list[:20]"]},{"cell_type":"markdown","metadata":{},"source":["We can customize that list as well.\n","\n","Let's say that we want to keep the word `\"for\"` in our final vocabulary, since it appears disproportionately often in the `misc.forsale` category. The code below removes that from the stopwords:"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Original list length: 179\n","List length after removing 'for': 178\n"]}],"source":["# Run this cell without changes\n","print(\"Original list length:\", len(stopwords_list))\n","stopwords_list.pop(stopwords_list.index(\"for\"))\n","print(\"List length after removing 'for':\", len(stopwords_list))"]},{"cell_type":"markdown","metadata":{},"source":["In the cell below, write a function `remove_stopwords` that takes in a list-like collection of strings (tokens) and returns only those that are not in the list of stopwords. (Use the `stopwords_list` in the global scope, so that we can later use `.apply` with this function.)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["# Replace None with appropriate code\n","def remove_stopwords(token_list):\n","    \"\"\"\n","    Given a list of tokens, return a list where the tokens\n","    that are also present in stopwords_list have been\n","    removed\n","    \"\"\"\n","    return [token for token in token_list if token not in stopwords_list]"]},{"cell_type":"markdown","metadata":{},"source":["Test it out on one example:"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m tokens_example \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_tokenized\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength with stopwords:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tokens_example))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tokens_example) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m110\u001b[39m\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"]}],"source":["# Run this cell without changes\n","tokens_example = X_train.iloc[100][\"text_tokenized\"]\n","print(\"Length with stopwords:\", len(tokens_example))\n","assert len(tokens_example) == 110\n","\n","tokens_example_without_stopwords = remove_stopwords(tokens_example)\n","print(\"Length without stopwords:\", len(tokens_example_without_stopwords))\n","assert len(tokens_example_without_stopwords) == 65"]},{"cell_type":"markdown","metadata":{},"source":["If that ran successfully, go ahead and apply it to the full `X_train`."]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[66], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_without_stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_tokenized\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(remove_stopwords)\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","X_train[\"text_without_stopwords\"] = X_train[\"text_tokenized\"].apply(remove_stopwords)"]},{"cell_type":"markdown","metadata":{},"source":["Now we can compare frequency distributions without stopwords:"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'text_without_stopwords'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'text_without_stopwords'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m setup_five_subplots()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_distribution_of_column_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext_without_stopwords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Frequencies without Stopwords\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m);\n","Cell \u001b[1;32mIn[49], line 38\u001b[0m, in \u001b[0;36mplot_distribution_of_column_by_category\u001b[1;34m(column, axes, title)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_distribution_of_column_by_category\u001b[39m(column, axes, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Frequency for\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(newsgroups_train\u001b[38;5;241m.\u001b[39mtarget_names):\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# Calculate frequency distribution for this subset\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m         all_words \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mexplode()\n\u001b[0;32m     39\u001b[0m         freq_dist \u001b[38;5;241m=\u001b[39m FreqDist(all_words)\n\u001b[0;32m     40\u001b[0m         top_10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfreq_dist\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)))\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'text_without_stopwords'"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x900 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Run this cell without changes\n","fig, axes = setup_five_subplots()\n","plot_distribution_of_column_by_category(\"text_without_stopwords\", axes)\n","fig.suptitle(\"Word Frequencies without Stopwords\", fontsize=24);"]},{"cell_type":"markdown","metadata":{},"source":["Ok, this seems to answer our question. The most common words differ significantly between categories now, meaning that hopefully our model will have an easier time distinguishing between them.\n","\n","Let's redo our modeling process, using `stopwords_list` when instantiating the vectorizer:"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[61], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(\n\u001b[0;32m      5\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39mstopwords_list\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Fit the vectorizer on X_train[\"text\"] and transform it\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Visually inspect the vectorized data\u001b[39;00m\n\u001b[0;32m     13\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mfrom_spmatrix(X_train_vectorized, columns\u001b[38;5;241m=\u001b[39mtfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","\n","# Instantiate the vectorizer\n","tfidf = TfidfVectorizer(\n","    max_features=10,\n","    stop_words=stopwords_list\n",")\n","\n","# Fit the vectorizer on X_train[\"text\"] and transform it\n","X_train_vectorized = tfidf.fit_transform(X_train[\"text\"])\n","\n","# Visually inspect the vectorized data\n","pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names_out())"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1, 2838]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[62], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier on X_train_vectorized and y_train\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m stopwords_removed_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m stopwords_removed_cv\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:351\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[1;32m--> 351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:517\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    516\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 517\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    463\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2838]"]}],"source":["# Run this cell without changes\n","\n","# Evaluate the classifier on X_train_vectorized and y_train\n","stopwords_removed_cv = cross_val_score(baseline_model, X_train_vectorized, y_train)\n","stopwords_removed_cv"]},{"cell_type":"markdown","metadata":{},"source":["How does this compare to our baseline?"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'baseline_cv' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[67], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseline:         \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbaseline_cv\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopwords removed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, stopwords_removed_cv\u001b[38;5;241m.\u001b[39mmean())\n","\u001b[1;31mNameError\u001b[0m: name 'baseline_cv' is not defined"]}],"source":["# Run this cell without changes\n","print(\"Baseline:         \", baseline_cv.mean())\n","print(\"Stopwords removed:\", stopwords_removed_cv.mean())"]},{"cell_type":"markdown","metadata":{},"source":["Looks like we have a marginal improvement, but still an improvement. So, to answer ***do we remove stopwords or not:*** yes, let's remove stopwords."]},{"cell_type":"markdown","metadata":{},"source":["### Using Custom Tokens\n","\n","Our next question is ***what should be counted as a token?***\n","\n","Recall that currently we are using the default token pattern, which finds words of two or more characters. What happens if we also *stem* those words, so that `swims` and `swimming` would count as the same token?\n","\n","Here we have provided a custom tokenizing function:"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","from nltk.stem.snowball import SnowballStemmer\n","stemmer = SnowballStemmer(language=\"english\")\n","\n","def stem_and_tokenize(document):\n","    tokens = tokenizer.tokenize(document)\n","    return [stemmer.stem(token) for token in tokens]"]},{"cell_type":"markdown","metadata":{},"source":["This uses `tokenizer` that we created earlier, as well as a new `stemmer` object. See an example below:"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[69], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal sample:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_tokenized\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m30\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStemmed sample: \u001b[39m\u001b[38;5;124m\"\u001b[39m, stem_and_tokenize(X_train\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])[\u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m30\u001b[39m])\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"]}],"source":["# Run this cell without changes\n","print(\"Original sample:\", X_train.iloc[100][\"text_tokenized\"][20:30])\n","print(\"Stemmed sample: \", stem_and_tokenize(X_train.iloc[100][\"text\"])[20:30])"]},{"cell_type":"markdown","metadata":{},"source":["We also need to stem our stopwords:"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["# Run this cell without changes\n","stemmed_stopwords = [stemmer.stem(word) for word in stopwords_list]"]},{"cell_type":"markdown","metadata":{},"source":["In the cells below, repeat the modeling process from earlier. This time when instantiating the `TfidfVectorizer`, specify:\n","\n","* `max_features=10` (same as previous)\n","* `stop_words=stemmed_stopwords` (modified)\n","* `tokenizer=stem_and_tokenize` (new)"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[71], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39mstemmed_stopwords, tokenizer\u001b[38;5;241m=\u001b[39mstem_and_tokenize)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Fit the vectorizer on X_train[\"text\"] and transform it\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Visually inspect the vectorized data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mfrom_spmatrix(X_train_vectorized, columns\u001b[38;5;241m=\u001b[39mtfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Replace None with appropriate code\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","# Instantiate the vectorizer\n","tfidf = TfidfVectorizer(max_features=10, stop_words=stemmed_stopwords, tokenizer=stem_and_tokenize)\n","\n","# Fit the vectorizer on X_train[\"text\"] and transform it\n","X_train_vectorized = tfidf.fit_transform(X_train[\"text\"])\n","\n","# Visually inspect the vectorized data\n","pd.DataFrame.sparse.from_spmatrix(X_train_vectorized, columns=tfidf.get_feature_names_out())"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [1, 2838]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[72], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier on X_train_vectorized and y_train\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m stemmed_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbaseline_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_vectorized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m stemmed_cv\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:351\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate metric(s) by cross-validation and also record fit/score times.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <multimetric_cross_validation>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;124;03m[0.28009951 0.3908844  0.22784907]\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    349\u001b[0m params \u001b[38;5;241m=\u001b[39m _check_params_groups_deprecation(fit_params, params, groups)\n\u001b[1;32m--> 351\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m cv \u001b[38;5;241m=\u001b[39m check_cv(cv, y, classifier\u001b[38;5;241m=\u001b[39mis_classifier(estimator))\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:517\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <3x1 sparse matrix ...>]\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    516\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 517\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:460\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    458\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    463\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1, 2838]"]}],"source":["# Run this cell without changes\n","\n","# Evaluate the classifier on X_train_vectorized and y_train\n","stemmed_cv = cross_val_score(baseline_model, X_train_vectorized, y_train)\n","stemmed_cv"]},{"cell_type":"markdown","metadata":{},"source":["How does this compare to our previous best modeling process?"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stopwords_removed_cv' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopwords removed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstopwords_removed_cv\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStemmed:          \u001b[39m\u001b[38;5;124m\"\u001b[39m, stemmed_cv\u001b[38;5;241m.\u001b[39mmean())\n","\u001b[1;31mNameError\u001b[0m: name 'stopwords_removed_cv' is not defined"]}],"source":["# Run this cell without changes\n","print(\"Stopwords removed:\", stopwords_removed_cv.mean())\n","print(\"Stemmed:          \", stemmed_cv.mean())"]},{"cell_type":"markdown","metadata":{},"source":["Great! Another improvement, a slightly bigger one than we got when just removing stopwords. So, our best modeling process for now is one where we remove stopwords, use the default token pattern, and stem our tokens with a snowball stemmer."]},{"cell_type":"markdown","metadata":{},"source":["### Domain-Specific Feature Engineering\n","\n","The way to really get the most information out of text data is by adding features beyond just vectorizing the tokens. This code will be completed for you, and it's okay if you don't fully understand everything that is happening, but we hope it helps you brainstorm for future projects!"]},{"cell_type":"markdown","metadata":{},"source":["#### Number of Sentences\n","\n","Does the number of sentences in a post differ by category? Let's investigate.\n","\n","Once again, there is a tool from NLTK that helps with this task."]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[74], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sent_tokenize\n\u001b[1;32m----> 4\u001b[0m sent_tokenize(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"]}],"source":["# Run this cell without changes\n","from nltk.tokenize import sent_tokenize\n","\n","sent_tokenize(X_train.iloc[100][\"text\"])"]},{"cell_type":"markdown","metadata":{},"source":["We can just take the length of this list to find the number of sentences:"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'iloc'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[75], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(sent_tokenize(\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m100\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n","\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'iloc'"]}],"source":["# Run this cell without changes\n","len(sent_tokenize(X_train.iloc[100][\"text\"]))"]},{"cell_type":"markdown","metadata":{},"source":["The following code adds a feature `num_sentences` to `X_train`:"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[76], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(sent_tokenize(x)))\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","X_train[\"num_sentences\"] = X_train[\"text\"].apply(lambda x: len(sent_tokenize(x)))"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"ename":"KeyError","evalue":"'num_sentences'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyError\u001b[0m: 'num_sentences'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[77], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m setup_five_subplots()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mplot_distribution_of_column_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_sentences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNumbers of Sentences for\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m fig\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistributions of Sentence Counts by Category\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m);\n","Cell \u001b[1;32mIn[49], line 38\u001b[0m, in \u001b[0;36mplot_distribution_of_column_by_category\u001b[1;34m(column, axes, title)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_distribution_of_column_by_category\u001b[39m(column, axes, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWord Frequency for\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, category \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(newsgroups_train\u001b[38;5;241m.\u001b[39mtarget_names):\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;66;03m# Calculate frequency distribution for this subset\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m         all_words \u001b[38;5;241m=\u001b[39m \u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX_train_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mexplode()\n\u001b[0;32m     39\u001b[0m         freq_dist \u001b[38;5;241m=\u001b[39m FreqDist(all_words)\n\u001b[0;32m     40\u001b[0m         top_10 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfreq_dist\u001b[38;5;241m.\u001b[39mmost_common(\u001b[38;5;241m10\u001b[39m)))\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[1;31mKeyError\u001b[0m: 'num_sentences'"]},{"data":{"image/png":"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","text/plain":["<Figure size 1500x900 with 5 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Run this cell without changes\n","fig, axes = setup_five_subplots()\n","plot_distribution_of_column_by_category(\"num_sentences\", axes, \"Numbers of Sentences for\")\n","fig.suptitle(\"Distributions of Sentence Counts by Category\", fontsize=24);"]},{"cell_type":"markdown","metadata":{},"source":["Does this seem like a useful feature? Maybe. The distributions differ a bit, but it's hard to know if our model will pick up on this information. Let's go ahead and keep it."]},{"cell_type":"markdown","metadata":{},"source":["#### Contains a Price\n","\n","The idea here is particularly to be able to distinguish the `misc.forsale` category, but it might also help with identifying the others. Let's use RegEx to check if the text contains a price:"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[78], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define a price as a dollar sign followed by 1-3 numbers,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# optional commas or decimals, 1-2 numbers after the decimal\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# (we're not too worried about accidentally matching malformed prices)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m price_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$(?:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,3}[,.]?)+(?:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m1,2})?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_price\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(price_query)\n\u001b[0;32m     10\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m setup_five_subplots()\n\u001b[0;32m     11\u001b[0m plot_distribution_of_column_by_category(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_price\u001b[39m\u001b[38;5;124m\"\u001b[39m, axes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFreqency of Posts Containing Prices for\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","\n","# Define a price as a dollar sign followed by 1-3 numbers,\n","# optional commas or decimals, 1-2 numbers after the decimal\n","# (we're not too worried about accidentally matching malformed prices)\n","price_query = r'\\$(?:\\d{1,3}[,.]?)+(?:\\\\d{1,2})?'\n","\n","X_train[\"contains_price\"] = X_train[\"text\"].str.contains(price_query)\n","\n","fig, axes = setup_five_subplots()\n","plot_distribution_of_column_by_category(\"contains_price\", axes, \"Freqency of Posts Containing Prices for\")\n","fig.suptitle(\"Distributions of Posts Containing Prices by Category\", fontsize=24);"]},{"cell_type":"markdown","metadata":{},"source":["As we expected, the `misc.forsale` category looks pretty different from the others. More than half of those posts contain prices, whereas the overwhelming majority of posts in other categories do not contain prices. Let's include this in our final model."]},{"cell_type":"markdown","metadata":{},"source":["#### Contains an Emoticon\n","\n","This is a bit silly, but we were wondering whether different categories feature different numbers of emoticons.\n","\n","Here we define an emoticon as an ASCII character representing eyes, an optional ASCII character representing a nose, and an ASCII character representing a mouth."]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[79], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m emoticon_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(?:[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m:;X=B][-^]?[)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m]3D([OP/\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m|])(?:(?=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms))\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m X_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_emoticon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(emoticon_query)\n\u001b[0;32m      7\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m setup_five_subplots()\n\u001b[0;32m      8\u001b[0m plot_distribution_of_column_by_category(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_emoticon\u001b[39m\u001b[38;5;124m\"\u001b[39m, axes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFreqency of Posts Containing Emoticons for\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","\n","emoticon_query = r'(?:[\\:;X=B][-^]?[)\\]3D([OP/\\\\|])(?:(?=\\s))'\n","\n","X_train[\"contains_emoticon\"] = X_train[\"text\"].str.contains(emoticon_query)\n","\n","fig, axes = setup_five_subplots()\n","plot_distribution_of_column_by_category(\"contains_emoticon\", axes, \"Freqency of Posts Containing Emoticons for\")\n","fig.suptitle(\"Distributions of Posts Containing Emoticons by Category\", fontsize=24);"]},{"cell_type":"markdown","metadata":{},"source":["Well, that was a lot less definitive. Emoticons are fairly rare across categories. But, there are some small differences so let's go ahead and keep it."]},{"cell_type":"markdown","metadata":{},"source":["#### Modeling with Vectorized Features + Engineered Features \n","\n","Let's combine our best vectorizer with these new features:"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[80], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(\n\u001b[0;32m      5\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m      6\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39mstemmed_stopwords,\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mstem_and_tokenize\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit the vectorizer on X_train[\"text\"] and transform it\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create a full df of vectorized + engineered features\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_train_vectorized_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_vectorized\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mtfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Run this cell without changes\n","\n","# Instantiate the vectorizer\n","tfidf = TfidfVectorizer(\n","    max_features=10,\n","    stop_words=stemmed_stopwords,\n","    tokenizer=stem_and_tokenize\n",")\n","\n","# Fit the vectorizer on X_train[\"text\"] and transform it\n","X_train_vectorized = tfidf.fit_transform(X_train[\"text\"])\n","\n","# Create a full df of vectorized + engineered features\n","X_train_vectorized_df = pd.DataFrame(X_train_vectorized.toarray(), columns=tfidf.get_feature_names_out())\n","preprocessed_X_train = pd.concat([\n","    X_train_vectorized_df, X_train[[\"num_sentences\", \"contains_price\", \"contains_emoticon\"]]\n","], axis=1)\n","preprocessed_X_train"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'preprocessed_X_train' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[81], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m preprocessed_cv \u001b[38;5;241m=\u001b[39m cross_val_score(baseline_model, \u001b[43mpreprocessed_X_train\u001b[49m, y_train)\n\u001b[0;32m      3\u001b[0m preprocessed_cv\n","\u001b[1;31mNameError\u001b[0m: name 'preprocessed_X_train' is not defined"]}],"source":["# Run this cell without changes\n","preprocessed_cv = cross_val_score(baseline_model, preprocessed_X_train, y_train)\n","preprocessed_cv"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stemmed_cv' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[82], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStemmed:           \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstemmed_cv\u001b[49m\u001b[38;5;241m.\u001b[39mmean())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFully preprocessed:\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessed_cv\u001b[38;5;241m.\u001b[39mmean())\n","\u001b[1;31mNameError\u001b[0m: name 'stemmed_cv' is not defined"]}],"source":["# Run this cell without changes\n","print(\"Stemmed:           \", stemmed_cv.mean())\n","print(\"Fully preprocessed:\", preprocessed_cv.mean())"]},{"cell_type":"markdown","metadata":{},"source":["Ok, another small improvement! We're still a bit below 50% accuracy, but we're getting improvements every time."]},{"cell_type":"markdown","metadata":{},"source":["### Increasing `max_features`\n","\n","Right now we are only allowing the model to look at the tf-idf of the top 10 most frequent tokens. If we allow it to look at all possible tokens, that could lead to high dimensionality issues (especially if we have more rows than columns), but there is a lot of room between 10 and `len(X_train)` features:"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["1"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","len(X_train)"]},{"cell_type":"markdown","metadata":{},"source":["(In other words, setting `max_features` to 2838 would mean an equal number of rows and columns, something that can cause problems for many model algorithms.)\n","\n","Let's try increasing `max_features` from 10 to 200:"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"ename":"TypeError","evalue":"list indices must be integers or slices, not str","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[84], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m tfidf \u001b[38;5;241m=\u001b[39m TfidfVectorizer(\n\u001b[0;32m      5\u001b[0m     max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[0;32m      6\u001b[0m     stop_words\u001b[38;5;241m=\u001b[39mstemmed_stopwords,\n\u001b[0;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mstem_and_tokenize\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Fit the vectorizer on X_train[\"text\"] and transform it\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m X_train_vectorized \u001b[38;5;241m=\u001b[39m tfidf\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Create a full df of vectorized + engineered features\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X_train_vectorized_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_train_vectorized\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mtfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n","\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"]}],"source":["# Replace None with appropriate code\n","\n","# Instantiate the vectorizer\n","tfidf = TfidfVectorizer(\n","    max_features=200,\n","    stop_words=stemmed_stopwords,\n","    tokenizer=stem_and_tokenize\n",")\n","\n","# Fit the vectorizer on X_train[\"text\"] and transform it\n","X_train_vectorized = tfidf.fit_transform(X_train[\"text\"])\n","\n","# Create a full df of vectorized + engineered features\n","X_train_vectorized_df = pd.DataFrame(X_train_vectorized.toarray(), columns=tfidf.get_feature_names_out())\n","final_X_train = pd.concat([\n","    X_train_vectorized_df, X_train[[\"num_sentences\", \"contains_price\", \"contains_emoticon\"]]\n","], axis=1)\n","final_X_train"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'final_X_train' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[85], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m final_cv \u001b[38;5;241m=\u001b[39m cross_val_score(baseline_model, \u001b[43mfinal_X_train\u001b[49m, y_train)\n\u001b[0;32m      4\u001b[0m final_cv\n","\u001b[1;31mNameError\u001b[0m: name 'final_X_train' is not defined"]}],"source":["# Run this cell without changes\n","\n","final_cv = cross_val_score(baseline_model, final_X_train, y_train)\n","final_cv"]},{"cell_type":"markdown","metadata":{},"source":["Nice! Our model was able to learn a lot more with these added features. Let's say this is our final modeling process and move on to a final evaluation."]},{"cell_type":"markdown","metadata":{},"source":["## 5. Evaluate a Final Model on the Test Set\n","\n","Instantiate the model, fit it on the full training set and check the score:"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'final_X_train' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[86], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m final_model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 4\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mfinal_X_train\u001b[49m, y_train)\n\u001b[0;32m      5\u001b[0m final_model\u001b[38;5;241m.\u001b[39mscore(final_X_train, y_train)\n","\u001b[1;31mNameError\u001b[0m: name 'final_X_train' is not defined"]}],"source":["# Run this cell without changes\n","final_model = MultinomialNB()\n","\n","final_model.fit(final_X_train, y_train)\n","final_model.score(final_X_train, y_train)"]},{"cell_type":"markdown","metadata":{},"source":["Create a vectorized version of `X_test`'s text:"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"ename":"NotFittedError","evalue":"The TF-IDF vectorizer is not fitted","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[87], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Note that we just transform, don't fit_transform\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m X_test_vectorized \u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2115\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, raw_documents):\n\u001b[0;32m   2100\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m \n\u001b[0;32m   2102\u001b[0m \u001b[38;5;124;03m    Uses the vocabulary and document frequencies (df) learned by fit (or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2113\u001b[0m \u001b[38;5;124;03m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   2114\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2115\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe TF-IDF vectorizer is not fitted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2117\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mtransform(raw_documents)\n\u001b[0;32m   2118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mtransform(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1632\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n","\u001b[1;31mNotFittedError\u001b[0m: The TF-IDF vectorizer is not fitted"]}],"source":["# Run this cell without changes\n","\n","# Note that we just transform, don't fit_transform\n","X_test_vectorized = tfidf.transform(X_test[\"text\"])"]},{"cell_type":"markdown","metadata":{},"source":["Feature engineering for `X_test`:"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[{"ename":"LookupError","evalue":"\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[88], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_price\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(price_query)\n\u001b[0;32m      4\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_emoticon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(emoticon_query)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n","File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","Cell \u001b[1;32mIn[88], line 2\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(\u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m      3\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_price\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(price_query)\n\u001b[0;32m      4\u001b[0m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_emoticon\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m X_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(emoticon_query)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[0m, in \u001b[0;36m_get_punkt_tokenizer\u001b[1;34m(language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_punkt_tokenizer\u001b[39m(language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    a lru cache for performance.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    :type language: str\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[0m, in \u001b[0;36mPunktTokenizer.__init__\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1743\u001b[0m     PunktSentenceTokenizer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1744\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[0m, in \u001b[0;36mPunktTokenizer.load_lang\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1747\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[1;32m-> 1749\u001b[0m     lang_dir \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m load_punkt_params(lang_dir)\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lang \u001b[38;5;241m=\u001b[39m lang\n","File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n","\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Administrator/nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Administrator\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"]}],"source":["# Run this cell without changes\n","X_test[\"num_sentences\"] = X_test[\"text\"].apply(lambda x: len(sent_tokenize(x)))\n","X_test[\"contains_price\"] = X_test[\"text\"].str.contains(price_query)\n","X_test[\"contains_emoticon\"] = X_test[\"text\"].str.contains(emoticon_query)"]},{"cell_type":"markdown","metadata":{},"source":["Putting it all together:"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'X_test_vectorized' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[89], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_test_vectorized_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mX_test_vectorized\u001b[49m\u001b[38;5;241m.\u001b[39mtoarray(), columns\u001b[38;5;241m=\u001b[39mtfidf\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n\u001b[0;32m      3\u001b[0m final_X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\n\u001b[0;32m      4\u001b[0m     X_test_vectorized_df, X_test[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_sentences\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_price\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontains_emoticon\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m      5\u001b[0m ], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m final_X_test\n","\u001b[1;31mNameError\u001b[0m: name 'X_test_vectorized' is not defined"]}],"source":["# Run this cell without changes\n","X_test_vectorized_df = pd.DataFrame(X_test_vectorized.toarray(), columns=tfidf.get_feature_names_out())\n","final_X_test = pd.concat([\n","    X_test_vectorized_df, X_test[[\"num_sentences\", \"contains_price\", \"contains_emoticon\"]]\n","], axis=1)\n","final_X_test"]},{"cell_type":"markdown","metadata":{},"source":["Scoring on the test set:"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'final_X_test' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[90], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run this cell without changes\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m final_model\u001b[38;5;241m.\u001b[39mscore(\u001b[43mfinal_X_test\u001b[49m, y_test)\n","\u001b[1;31mNameError\u001b[0m: name 'final_X_test' is not defined"]}],"source":["# Run this cell without changes\n","final_model.score(final_X_test, y_test)"]},{"cell_type":"markdown","metadata":{},"source":["Plotting a confusion matrix:"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'final_X_test' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[91], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConfusionMatrixDisplay\n\u001b[1;32m----> 5\u001b[0m cnf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, final_model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mfinal_X_test\u001b[49m))\n\u001b[0;32m      6\u001b[0m disp \u001b[38;5;241m=\u001b[39m ConfusionMatrixDisplay(confusion_matrix\u001b[38;5;241m=\u001b[39mcnf_matrix, display_labels\u001b[38;5;241m=\u001b[39mfinal_model\u001b[38;5;241m.\u001b[39mclasses_)\n\u001b[0;32m      7\u001b[0m disp\u001b[38;5;241m.\u001b[39mplot(cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n","\u001b[1;31mNameError\u001b[0m: name 'final_X_test' is not defined"]}],"source":["# Run this cell without changes\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","\n","cnf_matrix = confusion_matrix(y_test, final_model.predict(final_X_test))\n","disp = ConfusionMatrixDisplay(confusion_matrix=cnf_matrix, display_labels=final_model.classes_)\n","disp.plot(cmap=plt.cm.Blues)"]},{"cell_type":"markdown","metadata":{},"source":["Recall that these are the names associated with the labels:"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>target name</th>\n","    </tr>\n","    <tr>\n","      <th>target value</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>rec.sport.hockey</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sci.crypt</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>comp.windows.x</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>misc.forsale</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>talk.politics.misc</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     target name\n","target value                    \n","2               rec.sport.hockey\n","3                      sci.crypt\n","0                 comp.windows.x\n","1                   misc.forsale\n","4             talk.politics.misc"]},"execution_count":92,"metadata":{},"output_type":"execute_result"}],"source":["# Run this cell without changes\n","target_values_and_names = train_target_counts.drop(\"count\", axis=1)\n","target_values_and_names"]},{"cell_type":"markdown","metadata":{},"source":["### Interpreting Results\n","\n","Interpret the results seen above. How well did the model do? How does it compare to random guessing? What can you say about the cases that the model was most likely to mislabel? If this were a project and you were describing next steps, what might those be?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Replace None with appropriate text\n","\"\"\"\n","None\n","\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["## Summary\n","\n","In this lab, we used our NLP skills to clean, preprocess, explore, and fit models to text data for classification. This wasn't easy  great job!!"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":4}
